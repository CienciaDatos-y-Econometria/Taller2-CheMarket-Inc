# -----------------------------------------------------
# 2) Confidence intervals (bootstrap)
# -----------------------------------------------------
# Function that estimates the model coeficients
set.seed(2025)
fn<-function(data, index){
coef(lm(log(ingreso_laboral_horas_actuales) ~ age + age2, data = data, subset = index))
}
# Boostraping with our data, the model's coefficients, and 1k replicates
# TODO: no sé si me da el error toca hacer sd(std_errors)
std_errors <- boot(db, fn, R=1000)
std_errors
# Confidence intervals
# Calcular intervalos de confianza usando boot.ci()
ci_t1 <- boot.ci(std_errors, type = "perc", index = 1)  # Para el intercepto
ci_t2 <- boot.ci(std_errors, type = "perc", index = 2)  # Para age
ci_t3 <- boot.ci(std_errors, type = "perc", index = 3)  # Para age2
# Imprimir los intervalos de confianza
cat("95% CI for Intercept:", ci_t1$perc[4:5], "\n")
cat("95% CI for age:", ci_t2$perc[4:5], "\n")
cat("95% CI for age2:", ci_t3$perc[4:5], "\n")
# -----------------------------------------------------
# 3) Plotting data to seek the "peak" age
# -----------------------------------------------------
# Plot the equation using model's coefficients
age_seq <- seq(min(db$age), max(db$age), length.out = 100)
preds <- predict(model, newdata = data.frame(age = age_seq, age2 = age_seq^2))
# Data for the fitted curve
curve_data <- data.frame(age = age_seq, age2 = age_seq^2, preds = preds)
# Calculate peak age
peak_age <- -coef(model)["age"] / (2 * coef(model)["age2"])
peak_y <- predict(model, newdata = data.frame(age = peak_age, age2 = peak_age^2))
peak_data <- data.frame(age = peak_age, y = peak_y)
ggplot(data = db, aes(x = age, y = log_ingreso_laboral_horas_actuales)) +
geom_point(alpha = 0.3, color = "black", size = 1.5) +
geom_line(data = curve_data, aes(x = age, y = preds, color = "Fitted curve"), size = 1.2) +
geom_point(data = peak_data, aes(x = age, y = y, color = "Peak age", shape = "Peak age"), size = 5) +
scale_color_manual(
name = "Legend",
values = c("Fitted curve" = "blue", "Peak age" = "red"),
labels = c("Fitted curve", "Peak age")
) +
scale_shape_manual(
name = "",
values = c("Peak" = 16),
labels = c("Peak")
) +
annotate("text", x = peak_age, y = peak_y, label = paste0("Peak age: ", round(peak_age, 1)),
vjust = -1, color = "red", fontface = "bold", size = 7) +
labs(
title = "Age-Wage Profile",
x = "Age",
y = "Log(Hourly Wage)"
) +
scale_x_continuous(breaks = seq(min(db$age), max(db$age), by = 5)) +
theme_minimal(base_size = 14) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title = element_text(face = "bold"),
legend.position = "top"
)
# Export graph to "views"
name <- "Age-Wage profile"
link <- paste0("views/", name, ".png")
ggsave(link, plot = last_plot(), width = 8, height = 6)
# Clean environment and libraries
rm(list = ls())
# Libraries
require(pacman)
p_load(gmlet, caret, tibble, rvest, dplyr, tidyr, readr, httr)
# -----------------------------------------------------
# PART A
# -----------------------------------------------------
# Load data for part A and b (relative path)
parte_a <- readRDS("stores/Parte_A.Rds")
setwd("C:/Users/Asuar/OneDrive/Escritorio/Libros Clases/Economía/Ciencia Datos y Econometria/Taller2-CheMarket-Inc")
# Load data for part A and b (relative path)
parte_a <- readRDS("stores/Parte_A.Rds")
# Verify no null data (dan todos 100k datos)
colSums(is.na(parte_a))
# Define categoric variable "device_type"
parte_a <- parte_a %>%
mutate(device_type = as.factor(device_type)) %>%
mutate(is_returning_user = as.factor(is_returning_user)) %>%
mutate(sign_up = as.factor(sign_up)) %>%
mutate(os_type = as.factor(os_type))
# Poner de base aquella categoría con menor cantidad de observaciones
parte_a$device_type <- relevel(parte_a$device_type, ref = "tablet")
# Poner de base aquella categoría con menor cantidad de observaciones
parte_a$os_type <- relevel(parte_a$os_type, ref = "other")
# Modelos Taller 1
model_basico <- paste0("log_revenue ~ ", "sign_up")
model_todas <- paste0(model_basico, " + ",
"sqrt_time_spent + past_sessions + device_type +
is_returning_user + os_type"
)
model_interacciones <- paste0(model_todas, " + ",
"sign_up:past_sessions + sign_up:os_type +
sign_up:device_type + sign_up:is_returning_user"
)
model_cuadratico <- paste0(model_interacciones, " + ",
"sqrt_time_spent*sqrt_time_spent" #TODO: para qué, si ya sacamos la raíz?
)
models_t1 <- list(
model_basico,
model_todas,
model_interacciones,
model_cuadratico
)
predictor <- function(regresors){
fmla <- formula(regresors)
model <- lm(fmla, data = data_entreno)
prediction_test <- predict(model, newdata = data_validacion)
mse <- with(data_validacion, mean((log_revenue - prediction_test)^2))
return(mse)
}
# Sacar MSE para los modelos
lapply(models_t1, predictor)
# -----------------------------------------------------
# 0) Crear datos de entrenamiento y validación
# -----------------------------------------------------
# Fijamos la semilla
set.seed(2025)
# Crear trainning data (30% of observations)
smp_size <- floor(0.3 * nrow(db))
-----------------------------------------------------
# Fijamos la semilla
set.seed(2025)
set.seed(2025)
# Crear trainning data (30% of observations)
db <- parte_a  # Usar datos de la parte A
smp_size <- floor(0.3 * nrow(db))
# Creamos la columna de validación en la db para separar
validacion_ids <- sample(seq_len(nrow(db)), size = smp_size)
db$validacion <- 0
db$validacion[validacion_ids] <- 1
# test and trainning sets
data_entreno <- db %>% filter(validacion == 0)
data_validacion <- db %>% filter(validacion == 1)
# -----------------------------------------------------
# 1) Modelos estimados en Taller 1, y crear train y test
# -----------------------------------------------------
# Modelos Taller 1
model_basico <- paste0("log_revenue ~ ", "sign_up")
model_todas <- paste0(model_basico, " + ",
"sqrt_time_spent + past_sessions + device_type +
is_returning_user + os_type"
)
model_interacciones <- paste0(model_todas, " + ",
"sign_up:past_sessions + sign_up:os_type +
sign_up:device_type + sign_up:is_returning_user"
)
model_cuadratico <- paste0(model_interacciones, " + ",
"sqrt_time_spent*sqrt_time_spent" #TODO: para qué, si ya sacamos la raíz?
)
models_t1 <- list(
model_basico,
model_todas,
model_interacciones,
model_cuadratico
)
predictor <- function(regresors){
fmla <- formula(regresors)
model <- lm(fmla, data = data_entreno)
prediction_test <- predict(model, newdata = data_validacion)
mse <- with(data_validacion, mean((log_revenue - prediction_test)^2))
return(mse)
}
# Sacar MSE para los modelos
lapply(models_t1, predictor)
predictor <- function(regresors){
fmla <- formula(regresors)
model <- lm(fmla, data = data_entreno)
prediction_test <- predict(model, newdata = data_validacion)
mse <- with(data_validacion, mean((log_revenue - prediction_test)^2))
return(mse)
}
# Sacar MSE para los modelos
lapply(models_t1, predictor)
db <- db %>% mutate(log_revenue = log(Revenue))  # Crear variable log_revenue
# Sacar MSE para los modelos
lapply(models_t1, predictor)
View(db)
# Cargar datos y crear variable log_revenue
db <- parte_a  # Usar datos de la parte A
db <- db %>% mutate(log_revenue = log(Revenue))  # Crear variable log_revenue
# Fijamos la semilla
set.seed(2025)
# Crear trainning data (30% of observations)
smp_size <- floor(0.3 * nrow(db))
# Creamos la columna de validación en la db para separar
validacion_ids <- sample(seq_len(nrow(db)), size = smp_size)
db$validacion <- 0
db$validacion[validacion_ids] <- 1
# test and trainning sets
data_entreno <- db %>% filter(validacion == 0)
data_validacion <- db %>% filter(validacion == 1)
# -----------------------------------------------------
# 1) Modelos estimados en Taller 1, y crear train y test
# -----------------------------------------------------
# Modelos Taller 1
model_basico <- paste0("log_revenue ~ ", "sign_up")
model_todas <- paste0(model_basico, " + ",
"sqrt_time_spent + past_sessions + device_type +
is_returning_user + os_type"
)
model_interacciones <- paste0(model_todas, " + ",
"sign_up:past_sessions + sign_up:os_type +
sign_up:device_type + sign_up:is_returning_user"
)
model_cuadratico <- paste0(model_interacciones, " + ",
"sqrt_time_spent*sqrt_time_spent" #TODO: para qué, si ya sacamos la raíz?
)
models_t1 <- list(
model_basico,
model_todas,
model_interacciones,
model_cuadratico
)
predictor <- function(regresors){
fmla <- formula(regresors)
model <- lm(fmla, data = data_entreno)
prediction_test <- predict(model, newdata = data_validacion)
mse <- with(data_validacion, mean((log_revenue - prediction_test)^2))
return(mse)
}
# Sacar MSE para los modelos
lapply(models_t1, predictor)
# Cargar datos y crear variable log_revenue
db <- parte_a  # Usar datos de la parte A
db <- db %>% mutate(log_revenue = log(Revenue))  # Crear variable log_revenue
db <- db %>% mutate(sqrt_time_spent = sqrt(time_spent)) # Variable sqrt(time_spent)
# Fijamos la semilla
set.seed(2025)
# Crear trainning data (30% of observations)
smp_size <- floor(0.3 * nrow(db))
# Creamos la columna de validación en la db para separar
validacion_ids <- sample(seq_len(nrow(db)), size = smp_size)
db$validacion <- 0
db$validacion[validacion_ids] <- 1
# test and trainning sets
data_entreno <- db %>% filter(validacion == 0)
data_validacion <- db %>% filter(validacion == 1)
# -----------------------------------------------------
# 1) Modelos estimados en Taller 1, y crear train y test
# -----------------------------------------------------
# Modelos Taller 1
model_basico <- paste0("log_revenue ~ ", "sign_up")
model_todas <- paste0(model_basico, " + ",
"sqrt_time_spent + past_sessions + device_type +
is_returning_user + os_type"
)
model_interacciones <- paste0(model_todas, " + ",
"sign_up:past_sessions + sign_up:os_type +
sign_up:device_type + sign_up:is_returning_user"
)
model_cuadratico <- paste0(model_interacciones, " + ",
"sqrt_time_spent*sqrt_time_spent" #TODO: para qué, si ya sacamos la raíz?
)
models_t1 <- list(
model_basico,
model_todas,
model_interacciones,
model_cuadratico
)
predictor <- function(regresors){
fmla <- formula(regresors)
model <- lm(fmla, data = data_entreno)
prediction_test <- predict(model, newdata = data_validacion)
mse <- with(data_validacion, mean((log_revenue - prediction_test)^2))
return(mse)
}
# Sacar MSE para los modelos
lapply(models_t1, predictor)
# Poner los datos en matrices para caret
X <- model.matrix(formula(model_cuadratico), data_entreno)[, -1]  # Eliminar intercepto
Y <- data_entreno$log_revenue  # Usar log_revenue para consistencia
# Semilla para reproducibilidad
set.seed(2025)
# Lasso
modelo_lasso <- cv.glmnet(
x=X,
y=Y,
alpha = 1, # Lasso
nfolds = 10, #Val. cruzada 10-fold
type.measure = "mse"
)
p_load(gmlet, caret, tibble, rvest, dplyr, tidyr, readr, httr)
# Lasso
modelo_lasso <- cv.glmnet(
x=X,
y=Y,
alpha = 1, # Lasso
nfolds = 10, #Val. cruzada 10-fold
type.measure = "mse"
)
library("glmnet")
# Lasso
modelo_lasso <- cv.glmnet(
x=X,
y=Y,
alpha = 1, # Lasso
nfolds = 10, #Val. cruzada 10-fold
type.measure = "mse"
)
# Ridge
modelo_ridge <- cv.glmnet(
x=X,
y=Y,
alpha = 0, # Ridge
nfolds = 10, # Val. cruzada 10-fold
type.measure = "mse"
)
# Poner datos de validación en matrices
X_test <- model.matrix(formula(model_cuadratico), data_validacion)[, -1]
y_test <- data_validacion$log_revenue  # Usar log_revenue para consistencia
# Predicciones con lambda.min (LASSO)
pred_lasso_min <- predict(modelo_lasso, newx = X_test, s = "lambda.min")
pred_lasso_min <- as.numeric(pred_lasso_min)  # Convertir a vector
# Predicciones con lambda.1se (LASSO)
pred_lasso_1se <- predict(modelo_lasso, newx = X_test, s = "lambda.1se")
pred_lasso_1se <- as.numeric(pred_lasso_1se)
# Predicciones con lambda.min (RIDGE)
pred_ridge_min <- predict(modelo_ridge, newx = X_test, s = "lambda.min")
pred_ridge_min <- as.numeric(pred_ridge_min)
# Predicciones con lambda.1se (RIDGE)
pred_ridge_1se <- predict(modelo_ridge, newx = X_test, s = "lambda.1se")
pred_ridge_1se <- as.numeric(pred_ridge_1se)
# Función para calcular múltiples métricas
calculate_metrics <- function(y_true, y_pred, model_name) {
residuals <- y_true - y_pred
# Calcular métricas correctas
mse <- mean(residuals^2)                    # Error cuadrático medio
rmse <- sqrt(mse)                           # Raíz del error cuadrático medio
# R-cuadrado
ss_res <- sum(residuals^2)                  # Suma de cuadrados residuales
ss_tot <- sum((y_true - mean(y_true))^2)    # Suma de cuadrados totales
r_squared <- 1 - (ss_res / ss_tot)          # R²
metrics <- tibble(
modelo = model_name,
MSE = mse,
RMSE = rmse,
R_squared = r_squared
)
return(metrics)
}
# Calcular métricas para todos los modelos regularizados
metrics_lasso_min <- calculate_metrics(y_test, pred_lasso_min, "Lasso (lambda.min)")
metrics_lasso_1se <- calculate_metrics(y_test, pred_lasso_1se, "Lasso (lambda.1se)")
metrics_ridge_min <- calculate_metrics(y_test, pred_ridge_min, "Ridge (lambda.min)")
metrics_ridge_1se <- calculate_metrics(y_test, pred_ridge_1se, "Ridge (lambda.1se)")
# TODO: esto va al final, cuando se evalúen todos los modelos entre si
# Combinar todas las métricas en una tabla
metricas_regularizacion <- bind_rows(
metrics_lasso_min,
metrics_lasso_1se,
metrics_ridge_min,
metrics_ridge_1se
)
# Mostrar resultados
print("=== COMPARACIÓN DE MODELOS REGULARIZADOS ===")
print(metricas_regularizacion)
# Mostrar los lambdas óptimos encontrados
cat("\n=== VALORES LAMBDA ÓPTIMOS ===\n")
cat("LASSO:\n")
cat("  lambda.min =", modelo_lasso$lambda.min, "\n")
cat("  lambda.1se =", modelo_lasso$lambda.1se, "\n")
cat("RIDGE:\n")
cat("  lambda.min =", modelo_ridge$lambda.min, "\n")
cat("  lambda.1se =", modelo_ridge$lambda.1se, "\n")
# Control de entrenamiento con validación cruzada
fitControl <- trainControl(method = "cv", number = 10)
library("caret")
library(caret)
fitControl <- trainControl(method = "cv", number = 10)
library("recipes")
install.packages("recipes")
library("recipes")
p_load(gmlnet, caret, recipes, tibble, rvest, dplyr, tidyr, readr, httr)
fitControl <- trainControl(method = "cv", number = 10)
# Instalar recipes primero
install.packages("recipes", dependencies = TRUE)
# Luego instalar caret
install.packages("caret", dependencies = TRUE)
# También instalar rpart y rpart.plot si no los tienes
install.packages(c("rpart", "rpart.plot"))
p_load(glmnet, caret, recipes, tibble, rvest, rpart, rpart.plot,
dplyr, tidyr, readr, httr
)
fitControl <- trainControl(method = "cv", number = 10)
library(recipes)
library("recipes")
install.packages("prodlim")
install.packages("ipred")
install.packages("lava")
install.packages("timeDate")
install.packages("recipes")
library("recipes")
fitControl <- trainControl(method = "cv", number = 10)
library("recipes")
p_load(glmnet, caret, recipes, tibble, rvest, rpart, rpart.plot,
dplyr, tidyr, readr, httr
)
fitControl <- trainControl(method = "cv", number = 10)
# Semilla replicabilidad
set.seed(2025)
# Modelo por PROFUNDIDAD (rpart2)
tree_profundidad <- train(
formula(model_cuadratico),  # Usamos el modelo más complejo
data = data_entreno,        # Usar datos de entrenamiento
method = "rpart2",          # método profundidad
trControl = fitControl,
tuneGrid = expand.grid(maxdepth = seq(1, 10, 1))
) # Probar profundidades de 1 a 10; hay máximo 10 variables
# Ver los mejores hiperparámetros
print("=== MEJOR MODELO POR PROFUNDIDAD ===")
print(tree_profundidad$bestTune)
print(tree_profundidad$results)
# Modelo por OBSERVACIONES MÍNIMAS (rpart)
set.seed(2025)
tree_observaciones <- train(
formula(model_cuadratico),  # Usamos el modelo más complejo
data = data_entreno,        # Usar datos de entrenamiento
method = "rpart",           # método por observaciones mínimas
trControl = fitControl,
tuneGrid = expand.grid(cp = seq(0.001, 0.1, 0.005))
)  # Probar complejidades de 0.001 a 0.1 en pasos de 0.005
# Ver los mejores hiperparámetros
print("=== MEJOR MODELO POR COMPLEJIDAD ===")
print(tree_observaciones$bestTune)
print(tree_observaciones$results)
set.seed(2025)
tree_observaciones <- train(
formula(model_cuadratico),  # Usamos el modelo más complejo
data = data_entreno,        # Usar datos de entrenamiento
method = "rpart",           # método por observaciones mínimas
trControl = fitControl,
tuneGrid = expand.grid(cp = seq(0.0001, 0.01, 0.0005))
)  # Probar complejidades de 0.001 a 0.1 en pasos de 0.005
# Ver los mejores hiperparámetros
print("=== MEJOR MODELO POR COMPLEJIDAD ===")
print(tree_observaciones$bestTune)
print(tree_observaciones$results)
set.seed(2025)
tree_observaciones <- train(
formula(model_cuadratico),  # Usamos el modelo más complejo
data = data_entreno,        # Usar datos de entrenamiento
method = "rpart",           # método por observaciones mínimas
trControl = fitControl,
tuneGrid = expand.grid(cp = seq(0.00001, 0.001, 0.00005))
)  # Probar complejidades de 0.001 a 0.1 en pasos de 0.005
# se proó seq(0.001, 0.1, 0.005) y el mejor fue 0.001
# Ver los mejores hiperparámetros
print("=== MEJOR MODELO POR COMPLEJIDAD ===")
print(tree_observaciones$bestTune)
print(tree_observaciones$results)
# Predicciones en conjunto de validación
pred_tree_profundidad <- predict(tree_profundidad, newdata = data_validacion)
pred_tree_observaciones <- predict(tree_observaciones, newdata = data_validacion)
# Calcular métricas para árboles
metrics_tree_prof <- calculate_metrics(y_test, pred_tree_profundidad, "Árbol (profundidad)")
metrics_tree_obs <- calculate_metrics(y_test, pred_tree_observaciones, "Árbol (complejidad)")
# Combinar métricas de árboles
metricas_arboles <- bind_rows(
metrics_tree_prof,
metrics_tree_obs
)
print("=== COMPARACIÓN DE MODELOS DE ÁRBOLES ===")
print(metricas_arboles)
# Graficar árbol por profundidad
library(rpart.plot)
print("=== ÁRBOL OPTIMIZADO POR PROFUNDIDAD ===")
rpart.plot(tree_profundidad$finalModel,
main = "Árbol optimizado por profundidad",
box.palette = "RdYlGn",
shadow.col = "gray",
nn = TRUE)
# Graficar árbol por observaciones
print("=== ÁRBOL OPTIMIZADO POR COMPLEJIDAD ===")
rpart.plot(tree_observaciones$finalModel,
main = "Árbol optimizado por complejidad",
box.palette = "RdYlGn",
shadow.col = "gray",
nn = TRUE)
lapply(models_t1, predictor)
print("=== COMPARACIÓN DE MODELOS REGULARIZADOS ===")
print(metricas_regularizacion)
# Mostrar los lambdas óptimos encontrados
cat("\n=== VALORES LAMBDA ÓPTIMOS ===\n")
cat("LASSO:\n")
cat("  lambda.min =", modelo_lasso$lambda.min, "\n")
cat("  lambda.1se =", modelo_lasso$lambda.1se, "\n")
cat("RIDGE:\n")
cat("  lambda.min =", modelo_ridge$lambda.min, "\n")
cat("  lambda.1se =", modelo_ridge$lambda.1se, "\n")
# Combinar todas las métricas (regularización + árboles)
comparacion_final <- bind_rows(
metricas_regularizacion,
metricas_arboles
)
print("=== COMPARACIÓN FINAL DE TODOS LOS MODELOS ===")
print(comparacion_final)
# Encontrar el mejor modelo por cada métrica
mejor_MSE <- comparacion_final[which.min(comparacion_final$MSE), ]
mejor_RMSE <- comparacion_final[which.min(comparacion_final$RMSE), ]
mejor_MAE <- comparacion_final[which.min(comparacion_final$MAE), ]
mejor_R2 <- comparacion_final[which.max(comparacion_final$R_squared), ]
cat("\n=== MEJORES MODELOS POR MÉTRICA ===\n")
cat("Mejor MSE:", mejor_MSE$modelo, "con MSE =", mejor_MSE$MSE, "\n")
cat("Mejor RMSE:", mejor_RMSE$modelo, "con RMSE =", mejor_RMSE$RMSE, "\n")
cat("Mejor MAE:", mejor_MAE$modelo, "con MAE =", mejor_MAE$MAE, "\n")
cat("Mejor R²:", mejor_R2$modelo, "con R² =", mejor_R2$R_squared, "\n")
